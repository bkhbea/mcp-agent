# Model Context Protocol (MCP) â€“ Multi-Server Demo

This repository demonstrates a complete MCP pipeline using:
- A database MCP server
- A file MCP server
- A local LLM (Ollama / llama3)
- An agent that plans and executes multi-step workflows

## What this shows
- Tool vs resource separation
- MCP server chaining
- LLM planning vs agent execution
- Prompt design for MCP

## Requirements
- Python 3.10+
- Ollama
- llama3 model

## Setup

1. Clone the repo
2. Create a virtual environment
3. Install dependencies
4. Run the MCP servers
5. Run the agent

(see detailed steps below)

To Run the exmaple:
1. Make sure you downlaod Ollama
2. run ollama server (ollama serve)
3. To generate a new database (users.db), run helpers/init_db.py
5. pythoon agent/mcp_agent.py

servers/db_server.py - has all data access fucntion
servers/file_server.py - has all file actions.

If you would like a real-world example agent with full like cycle
which utilizes, DAG, execution layers and Parallelism

First this is this is the prompt:
========================= Prompt ===================
You are an assistant that can call tools via MCP.

### Database tools (all on server "db"):
{
  "get_user_by_id": ["id"],
  "list_users": ["name_filter", "email_filter"],
  "create_user": ["name", "email"],
  "update_user": ["id", "name", "email"],
  "delete_user": ["id"]
}

### File tools (all on server "file"):
{
  "read_file": ["path"],
  "write_file": ["path", "content"]
}

### File write action MUST use:
{
  "type": "tool",
  "server": "file",
  "tool": "write_file",
  "arguments": {
    "path": "<file_path>",
    "content": "<string_content>"
  }
}

### File read action MUST use:
{
  "type": "resource",
  "server": "file",
  "tool": "read_file",
  "arguments": {
    "uri": "file://<file_path>/"  
  }
  
}

### Database tool action MUST use:
{
  "type": "tool",
  "server": "db",
  "tool": "<tool_name>",
  "arguments": { ... }
}

### Rules:
- STRICTLY FOLLOW THESE RULES AND IF YOU CANNOT, STOP AND STATE THE REASON 
- Respond ONLY with valid JSON and ONLY JSON 
- Respond as a JSON array of actions (tools or resources)
- Each element MUST contain:
  - "tool"
  - "arguments"
- Do NOT include comments
- Do NOT include explanations
- Do NOT invent tools
- "arguments" MUST be a JSON object with named fields


### User request:
1. Create 3 users:
   - Alice (alice@example.com)
   - Bob (bon@example.com)
   - Charlie (chuck@example.com)
2. Write Alice user and bob user to bob_alice.txt - This should happen ONLY in one step
3. Write Charlie user to charlie.txt
4. list all users
5. Write users list to user_list.json
6. read user_list.json
===================================

Based on the above prompt, the below plan was generated by Ollama LLM:
================== LLM Generated Plan ===============
{
    "type": "tool",
    "server": "db",
    "tool": "create_user",
    "arguments": {
      "name": "Alice",
      "email": "alice@example.com"
    }
  },
  {
    "type": "tool",
    "server": "db",
    "tool": "create_user",
    "arguments": {
      "name": "Bob",
      "email": "bon@example.com"
    }
  },
  {
    "type": "tool",
    "server": "db",
    "tool": "create_user",
    "arguments": {
      "name": "Charlie",
      "email": "chuck@example.com"
    }
  },
  {
    "type": "tool",
    "server": "file",
    "tool": "write_file",
    "arguments": {
      "path": "bob_alice.txt",
      "content": "{\"id\": 1, \"name\": \"Alice\", \"email\": \"alice@example.com\"}\n{\"id\": 2, \"name\": \"Bob\", \"email\": \"bon@example.com\"}"
    }
  },
  {
    "type": "tool",
    "server": "file",
    "tool": "write_file",
    "arguments": {
      "path": "charlie.txt",
      "content": "{\"id\": 3, \"name\": \"Charlie\", \"email\": \"chuck@example.com\"}"
    }
  },
  {
    "type": "tool",
    "server": "db",
    "tool": "list_users",
    "arguments": {}
  },
  {
    "type": "tool",
    "server": "file",
    "tool": "write_file",
    "arguments": {
      "path": "user_list.json",
      "content": "{\"users\": [...]}"
    }
  },
  {
    "type": "resource",
    "server": "file",
    "tool": "read_file",
    "arguments": {
      "uri": "file:///user_list.json/"
    }
  }
]
==============================================================


